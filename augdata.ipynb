{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SksQoB6ulPGf"
   },
   "source": [
    "Load DataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 92789,
     "status": "ok",
     "timestamp": 1690348419425,
     "user": {
      "displayName": "林志叡",
      "userId": "10479465330995837297"
     },
     "user_tz": -480
    },
    "id": "yqX02yLhnHYx",
    "outputId": "5d2091cb-76e3-429c-c9ef-c94279c171ce"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Oct 26 07:20:53 2023       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 536.67                 Driver Version: 536.67       CUDA Version: 12.2     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                     TCC/WDDM  | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA GeForce RTX 2060      WDDM  | 00000000:01:00.0  On |                  N/A |\n",
      "|  0%   49C    P2              30W / 170W |   5587MiB /  6144MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|    0   N/A  N/A      7124    C+G   ...cal\\Microsoft\\OneDrive\\OneDrive.exe    N/A      |\n",
      "|    0   N/A  N/A      7856    C+G   ....0_x64__8wekyb3d8bbwe\\HxOutlook.exe    N/A      |\n",
      "|    0   N/A  N/A      8596    C+G   C:\\Windows\\explorer.exe                   N/A      |\n",
      "|    0   N/A  N/A      9588    C+G   ...translator 9.1.0\\copytranslator.exe    N/A      |\n",
      "|    0   N/A  N/A      9684      C   ...anaconda3\\envs\\unet_tf26\\python.exe    N/A      |\n",
      "|    0   N/A  N/A     10128    C+G   ....Search_cw5n1h2txyewy\\SearchApp.exe    N/A      |\n",
      "|    0   N/A  N/A     12948    C+G   ...t.LockApp_cw5n1h2txyewy\\LockApp.exe    N/A      |\n",
      "|    0   N/A  N/A     13584    C+G   ...ekyb3d8bbwe\\PhoneExperienceHost.exe    N/A      |\n",
      "|    0   N/A  N/A     14840    C+G   ...ta\\Local\\Programs\\Notion\\Notion.exe    N/A      |\n",
      "|    0   N/A  N/A     15444    C+G   ...ata\\Local\\LINE\\bin\\current\\LINE.exe    N/A      |\n",
      "|    0   N/A  N/A     20360    C+G   ...ft Office\\root\\Office16\\WINWORD.EXE    N/A      |\n",
      "|    0   N/A  N/A     21624    C+G   ...gin\\LineCall\\1.0.0.692\\LineCall.exe    N/A      |\n",
      "|    0   N/A  N/A     22232    C+G   ...crosoft\\Edge\\Application\\msedge.exe    N/A      |\n",
      "|    0   N/A  N/A     23284    C+G   ...oogle\\Chrome\\Application\\chrome.exe    N/A      |\n",
      "|    0   N/A  N/A     23792    C+G   ...siveControlPanel\\SystemSettings.exe    N/A      |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "#from google.colab import drive\n",
    "#drive.mount('/content/drive')\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import Sequence\n",
    "from tensorflow.keras import *\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras import Input, Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Physical devices cannot be modified after being initialized",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32md:\\Users\\ru83m\\Desktop\\CFD_train\\augdata.ipynb 儲存格 4\u001b[0m line \u001b[0;36m3\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Users/ru83m/Desktop/CFD_train/augdata.ipynb#W3sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mtf\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Users/ru83m/Desktop/CFD_train/augdata.ipynb#W3sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m physycal_devices\u001b[39m=\u001b[39mtf\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mlist_physical_devices(\u001b[39m'\u001b[39m\u001b[39mGPU\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/Users/ru83m/Desktop/CFD_train/augdata.ipynb#W3sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m tf\u001b[39m.\u001b[39;49mconfig\u001b[39m.\u001b[39;49mexperimental\u001b[39m.\u001b[39;49mset_memory_growth(physycal_devices[\u001b[39m0\u001b[39;49m], \u001b[39mTrue\u001b[39;49;00m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Users/ru83m/Desktop/CFD_train/augdata.ipynb#W3sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m tf\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mset_memory_growth(physycal_devices[\u001b[39m1\u001b[39m], \u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Users/ru83m/Desktop/CFD_train/augdata.ipynb#W3sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m tf\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mset_synchronous_execution(\u001b[39mFalse\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\ru83m\\anaconda3\\envs\\unet_tf26\\lib\\site-packages\\tensorflow\\python\\framework\\config.py:707\u001b[0m, in \u001b[0;36mset_memory_growth\u001b[1;34m(device, enable)\u001b[0m\n\u001b[0;32m    682\u001b[0m \u001b[39m@tf_export\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mconfig.experimental.set_memory_growth\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m    683\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mset_memory_growth\u001b[39m(device, enable):\n\u001b[0;32m    684\u001b[0m \u001b[39m  \u001b[39m\u001b[39m\"\"\"Set if memory growth should be enabled for a `PhysicalDevice`.\u001b[39;00m\n\u001b[0;32m    685\u001b[0m \n\u001b[0;32m    686\u001b[0m \u001b[39m  If memory growth is enabled for a `PhysicalDevice`, the runtime initialization\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    705\u001b[0m \u001b[39m    RuntimeError: Runtime is already initialized.\u001b[39;00m\n\u001b[0;32m    706\u001b[0m \u001b[39m  \"\"\"\u001b[39;00m\n\u001b[1;32m--> 707\u001b[0m   context\u001b[39m.\u001b[39;49mcontext()\u001b[39m.\u001b[39;49mset_memory_growth(device, enable)\n",
      "File \u001b[1;32mc:\\Users\\ru83m\\anaconda3\\envs\\unet_tf26\\lib\\site-packages\\tensorflow\\python\\eager\\context.py:1501\u001b[0m, in \u001b[0;36mContext.set_memory_growth\u001b[1;34m(self, dev, enable)\u001b[0m\n\u001b[0;32m   1498\u001b[0m   \u001b[39mreturn\u001b[39;00m\n\u001b[0;32m   1500\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_context_handle \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m-> 1501\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\n\u001b[0;32m   1502\u001b[0m       \u001b[39m\"\u001b[39m\u001b[39mPhysical devices cannot be modified after being initialized\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   1504\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_memory_growth_map[dev] \u001b[39m=\u001b[39m enable\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Physical devices cannot be modified after being initialized"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "physycal_devices=tf.config.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(physycal_devices[0], True)\n",
    "tf.config.experimental.set_memory_growth(physycal_devices[1], True)\n",
    "tf.config.experimental.set_synchronous_execution(False)\n",
    "print(tf.__version__)\n",
    "# 检查 TensorFlow 是否正确识别了 GPU\n",
    "#print(\"GPU is available:\", tf.test.is_gpu_available())\n",
    "# 打印 CUDA 版本和 cuDNN 版本信息\n",
    "print(\"CUDA version:\", tf.test.is_built_with_cuda())\n",
    "#print(\"cuDNN version:\", tf.test.is_built_with_cudnn())\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    for i, gpu in enumerate(gpus):\n",
    "        print(f\"GPU {i+1}: {gpu.name}, device_type={gpu.device_type},GPU Memory:{tf.config.experimental.get_memory_growth(gpu)}\")\n",
    "else:\n",
    "    print(\"No GPU devices found.\")\n",
    "# 设置只可见第二个 GPU 设备\n",
    "#import os\n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 16854,
     "status": "ok",
     "timestamp": 1690375024112,
     "user": {
      "displayName": "林志叡",
      "userId": "10479465330995837297"
     },
     "user_tz": -480
    },
    "id": "aPsfn4DC3XDt"
   },
   "outputs": [],
   "source": [
    "class DataGenerator_for_two_branch(Sequence):\n",
    "\n",
    "    def __init__(self, img_paths, label_paths, img_size, batch_size):\n",
    "        self.img_paths = img_paths\n",
    "        self.label_paths = label_paths\n",
    "        self.img_size = img_size\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img_start_idx, img_end_idx = self.index_batch_to_image(index)\n",
    "\n",
    "        img_path_list = self.img_paths[img_start_idx:img_end_idx]\n",
    "        label_path_list = self.label_paths[img_start_idx:img_end_idx]\n",
    "\n",
    "        X = [self.load_and_preprocess_image(img_path) for img_path in img_path_list]\n",
    "        Y = [self.load_and_preprocess_image(label_path) for label_path in label_path_list]\n",
    "\n",
    "        return np.array(X), np.array(Y)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_paths) // self.batch_size\n",
    "\n",
    "    def index_batch_to_image(self, batch_index):\n",
    "        image_index_start = batch_index * self.batch_size\n",
    "        image_index_end = (batch_index + 1) * self.batch_size\n",
    "\n",
    "        return image_index_start, image_index_end\n",
    "\n",
    "    def load_and_preprocess_image(self, img_path):\n",
    "        img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "        img = cv2.resize(img, self.img_size)\n",
    "        img = img / 255.0\n",
    "        img = np.expand_dims(img, axis=-1)\n",
    "        return img\n",
    "\n",
    "\n",
    "def get_paths_with_prefix(img_folder, label_folder, prefix_to_keep):\n",
    "    img_paths = sorted([os.path.join(img_folder, file) for file in os.listdir(img_folder) if file.startswith(prefix_to_keep)])\n",
    "    label_paths = sorted([os.path.join(label_folder, file) for file in os.listdir(label_folder) if file.startswith(prefix_to_keep)])\n",
    "    return img_paths, label_paths\n",
    "\n",
    "# 设置路径\n",
    "img_folder = \"train\"\n",
    "label_folder = \"train_mask\"\n",
    "val_folder = \"val\"\n",
    "valmask_folder = \"val_mask\"\n",
    "\n",
    "input_shape = 256\n",
    "batch_size = 8\n",
    "img_size = (input_shape, input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_history(history, validation : bool = False):\n",
    "    if validation:\n",
    "        # Loss\n",
    "        fig, axes = plt.subplots(figsize= (20,5))\n",
    "        # Train\n",
    "        axes.plot(history.epoch, history.history['loss'], color= 'r',  label = 'Train')\n",
    "        axes.plot(history.epoch, history.history['val_loss'], color = 'b', label = 'Val')\n",
    "        axes.set_xlabel('Epoch')\n",
    "        axes.set_ylabel('Loss')\n",
    "        axes.legend()\n",
    "        # Acc\n",
    "        fig, axes = plt.subplots(figsize= (20,5))\n",
    "        # Train\n",
    "        axes.plot(history.epoch, history.history['accuracy'], color= 'r',  label = 'Train')\n",
    "        axes.plot(history.epoch, history.history['val_accuracy'], color = 'b', label = 'Val')\n",
    "        axes.set_xlabel('Epoch')\n",
    "        axes.set_ylabel('accuracy')\n",
    "        axes.legend()\n",
    "        # Mean Iou\n",
    "        fig, axes = plt.subplots(figsize= (20,5))\n",
    "        # Train\n",
    "        #axes.plot(history.epoch, history.history['mean_iou'], color= 'r',  label = 'Train')\n",
    "        #axes.plot(history.epoch, history.history['val_mean_iou'], color = 'b', label = 'Val')\n",
    "        #axes.set_xlabel('Epoch')\n",
    "        #axes.set_ylabel('MeanIoU')\n",
    "        #axes.legend()\n",
    "    else:\n",
    "        fig, axes = plt.subplots(1,4, figsize= (20,5))\n",
    "        # loss\n",
    "        axes[0].plot(history.epoch, history.history['loss'])\n",
    "        axes[0].set_title('Train')\n",
    "        axes[0].set_xlabel('Epoch')\n",
    "        axes[0].set_ylabel('Loss')\n",
    "        # Acc\n",
    "        axes[1].plot(history.epoch, history.history['accuracy'])\n",
    "        axes[1].set_title('Train')\n",
    "        axes[1].set_xlabel('Epoch')\n",
    "        axes[1].set_ylabel('Acc')\n",
    "        # Mean Iou\n",
    "        #axes[2].plot(history.epoch, history.history['mean_iou'])\n",
    "        #axes[2].set_title('Train')\n",
    "        #axes[2].set_xlabel('Epoch')\n",
    "        #axes[2].set_ylabel('MeanIoU') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "class PReLU(tf.keras.layers.Layer):\n",
    "    def __init__(self, num_parameters=1, init=0.25):\n",
    "        super(PReLU, self).__init__()\n",
    "        self.num_parameters = num_parameters\n",
    "        self.alpha = self.add_weight(shape=(num_parameters,),\n",
    "                                     initializer=tf.keras.initializers.Constant(init),\n",
    "                                     trainable=True)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        pos = tf.nn.relu(inputs)\n",
    "        neg = self.alpha * (inputs - tf.abs(inputs)) * 0.5\n",
    "        return pos + neg\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kLD6ecNtDEY8"
   },
   "source": [
    "Original Model (UNET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 1411,
     "status": "ok",
     "timestamp": 1690376167626,
     "user": {
      "displayName": "林志叡",
      "userId": "10479465330995837297"
     },
     "user_tz": -480
    },
    "id": "oi9R_qweAVhs"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 256, 256, 1) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 256, 256, 64) 4194944     input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 256, 256, 64) 4231232     conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, 128, 128, 64) 0           conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 128, 128, 128 2171008     max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, 128, 128, 128 2244736     conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2D)  (None, 64, 64, 128)  0           conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, 64, 64, 256)  1343744     max_pooling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, 64, 64, 256)  1638656     conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2D)  (None, 32, 32, 256)  0           conv2d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (None, 32, 32, 512)  1704448     max_pooling2d_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)              (None, 32, 32, 512)  2884096     conv2d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 32, 32, 512)  0           conv2d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2D)  (None, 16, 16, 512)  0           dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)              (None, 16, 16, 1024) 4981760     max_pooling2d_7[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)              (None, 16, 16, 1024) 9700352     conv2d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 16, 16, 1024) 0           conv2d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_4 (UpSampling2D)  (None, 32, 32, 1024) 0           dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)              (None, 32, 32, 512)  2621952     up_sampling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 32, 32, 1024) 0           dropout_2[0][0]                  \n",
      "                                                                 conv2d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)              (None, 32, 32, 512)  5243392     concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)              (None, 32, 32, 512)  2884096     conv2d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_5 (UpSampling2D)  (None, 64, 64, 512)  0           conv2d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)              (None, 64, 64, 256)  1573120     up_sampling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 64, 64, 512)  0           conv2d_29[0][0]                  \n",
      "                                                                 conv2d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_38 (Conv2D)              (None, 64, 64, 256)  2228480     concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_39 (Conv2D)              (None, 64, 64, 256)  1638656     conv2d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_6 (UpSampling2D)  (None, 128, 128, 256 0           conv2d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_40 (Conv2D)              (None, 128, 128, 128 2228352     up_sampling2d_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (None, 128, 128, 256 0           conv2d_27[0][0]                  \n",
      "                                                                 conv2d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_41 (Conv2D)              (None, 128, 128, 128 2392192     concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_42 (Conv2D)              (None, 128, 128, 128 2244736     conv2d_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_7 (UpSampling2D)  (None, 256, 256, 128 0           conv2d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_43 (Conv2D)              (None, 256, 256, 64) 4227136     up_sampling2d_7[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_7 (Concatenate)     (None, 256, 256, 128 0           conv2d_25[0][0]                  \n",
      "                                                                 conv2d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_44 (Conv2D)              (None, 256, 256, 64) 4268096     concatenate_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_45 (Conv2D)              (None, 256, 256, 64) 4231232     conv2d_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_46 (Conv2D)              (None, 256, 256, 2)  132226      conv2d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_47 (Conv2D)              (None, 256, 256, 1)  3           conv2d_46[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 71,008,645\n",
      "Trainable params: 71,008,645\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import *\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras import Input, Model\n",
    "\n",
    "def unet(input_shape):\n",
    "    inputs = Input(input_shape)\n",
    "\n",
    "    # Encoder\n",
    "    conv1 = Conv2D(64, 3, activation='PReLU', padding='same')(inputs)\n",
    "    conv1 = Conv2D(64, 3, activation='PReLU', padding='same')(conv1)\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "\n",
    "    conv2 = Conv2D(128, 3, activation='PReLU', padding='same')(pool1)\n",
    "    conv2 = Conv2D(128, 3, activation='PReLU', padding='same')(conv2)\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "\n",
    "    conv3 = Conv2D(256, 3, activation='PReLU', padding='same')(pool2)\n",
    "    conv3 = Conv2D(256, 3, activation='PReLU', padding='same')(conv3)\n",
    "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "\n",
    "    conv4 = Conv2D(512, 3, activation='PReLU', padding='same')(pool3)\n",
    "    conv4 = Conv2D(512, 3, activation='PReLU', padding='same')(conv4)\n",
    "    drop4 = Dropout(0.5)(conv4)\n",
    "    pool4 = MaxPooling2D(pool_size=(2, 2))(drop4)\n",
    "\n",
    "    # Bottleneck\n",
    "    conv5 = Conv2D(1024, 3, activation='PReLU', padding='same')(pool4)\n",
    "    conv5 = Conv2D(1024, 3, activation='PReLU', padding='same')(conv5)\n",
    "    drop5 = Dropout(0.5)(conv5)\n",
    "\n",
    "    # Decoder\n",
    "    up6 = Conv2D(512, 2, activation='PReLU', padding='same')(UpSampling2D(size=(2, 2))(drop5))\n",
    "    merge6 = concatenate([drop4, up6], axis=3)\n",
    "    conv6 = Conv2D(512, 3, activation='PReLU', padding='same')(merge6)\n",
    "    conv6 = Conv2D(512, 3, activation='PReLU', padding='same')(conv6)\n",
    "\n",
    "    up7 = Conv2D(256, 2, activation='PReLU', padding='same')(UpSampling2D(size=(2, 2))(conv6))\n",
    "    merge7 = concatenate([conv3, up7], axis=3)\n",
    "    conv7 = Conv2D(256, 3, activation='PReLU', padding='same')(merge7)\n",
    "    conv7 = Conv2D(256, 3, activation='PReLU', padding='same')(conv7)\n",
    "\n",
    "    up8 = Conv2D(128, 2, activation='PReLU', padding='same')(UpSampling2D(size=(2, 2))(conv7))\n",
    "    merge8 = concatenate([conv2, up8], axis=3)\n",
    "    conv8 = Conv2D(128, 3, activation='PReLU', padding='same')(merge8)\n",
    "    conv8 = Conv2D(128, 3, activation='PReLU', padding='same')(conv8)\n",
    "\n",
    "    up9 = Conv2D(64, 2, activation='PReLU', padding='same')(UpSampling2D(size=(2, 2))(conv8))\n",
    "    merge9 = concatenate([conv1, up9], axis=3)\n",
    "    conv9 = Conv2D(64, 3, activation='PReLU', padding='same')(merge9)\n",
    "    conv9 = Conv2D(64, 3, activation='PReLU', padding='same')(conv9)\n",
    "    conv9 = Conv2D(2, 3, activation = 'PReLU', padding = 'same', kernel_initializer = 'he_normal')(conv9)\n",
    "    # Output\n",
    "    outputs = Conv2D(1, 1, activation='sigmoid')(conv9)\n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    model.summary()\n",
    "    \n",
    "    return model\n",
    "\n",
    "input_shape = (256, 256, 1)\n",
    "model = unet(input_shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "顯示載入資料集與資料及數量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 修改show_random_images函数，使其接受img_paths和label_paths作为参数\n",
    "def show_random_images(img_paths, label_paths, num_samples=5):\n",
    "    # 从图像路径列表中随机选择 num_samples 个索引\n",
    "    random_indices = random.sample(range(len(img_paths)), num_samples)\n",
    "\n",
    "    # 创建一个 (num_samples, 2) 的子图布局\n",
    "    fig, axes = plt.subplots(num_samples, 2, figsize=(10, 10))\n",
    "\n",
    "    # 遍历随机选择的索引\n",
    "    for i, index in enumerate(random_indices):\n",
    "        img_path = img_paths[index]\n",
    "        label_path = label_paths[index]\n",
    "\n",
    "        # 加载原图像和对应的 mask 图像\n",
    "        img = cv2.imread(img_path)\n",
    "        label = cv2.imread(label_path)\n",
    "\n",
    "        # 显示原图像\n",
    "        axes[i, 0].imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "        axes[i, 0].set_title('Original Image')\n",
    "\n",
    "        # 显示 mask 图像\n",
    "        axes[i, 1].imshow(cv2.cvtColor(label, cv2.COLOR_BGR2RGB))\n",
    "        axes[i, 1].set_title('Mask Image')\n",
    "\n",
    "\n",
    "    # 确保子图之间不重叠\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def Print(train_gen,val_gen):\n",
    "    num_images = len(train_gen.img_paths)\n",
    "    num_images1 = len(train_gen.label_paths)\n",
    "    num_images2 = len(val_gen.img_paths)\n",
    "    num_images3 = len(val_gen.label_paths)\n",
    "    print(\"圖像数量为:\", num_images,num_images1,num_images2,num_images3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "資料擴增函示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "def augment_data(input_image_folder, input_label_folder, output_image_folder, output_label_folder, num_augmentations=30):\n",
    "    # 创建图像数据生成器\n",
    "    datagen = ImageDataGenerator(\n",
    "        zca_whitening=False,\n",
    "        rotation_range=0.2,\n",
    "        width_shift_range=0.05,\n",
    "        height_shift_range=0.05,\n",
    "        shear_range=0.05,\n",
    "        zoom_range=0.05,\n",
    "        horizontal_flip=True,\n",
    "        fill_mode=\"reflect\"\n",
    "    )\n",
    "\n",
    "    # 检查输出文件夹是否存在，如果不存在则创建它\n",
    "    if not os.path.exists(output_image_folder):\n",
    "        os.makedirs(output_image_folder)\n",
    "\n",
    "    if not os.path.exists(output_label_folder):\n",
    "        os.makedirs(output_label_folder)\n",
    "\n",
    "    image_filenames = [filename for filename in os.listdir(input_image_folder) if filename.endswith(\".png\")]\n",
    "    label_filenames = [filename for filename in os.listdir(input_label_folder) if filename.endswith(\".png\")]\n",
    "\n",
    "    # 存储所有数据增强后的图像和标签\n",
    "    augmented_images = []\n",
    "    augmented_labels = []\n",
    "    augmented_image_paths = []\n",
    "    augmented_label_paths = []\n",
    "\n",
    "    for i, (input_image_filename, input_label_filename) in enumerate(zip(image_filenames, label_filenames)):\n",
    "        img_path = os.path.join(input_image_folder, input_image_filename)\n",
    "        label_path = os.path.join(input_label_folder, input_label_filename)\n",
    "\n",
    "        img = cv2.imread(img_path)\n",
    "        label = cv2.imread(label_path)\n",
    "\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        label = cv2.cvtColor(label, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        for j in range(num_augmentations):\n",
    "            # 使用不同的随机种子对图像和标签进行数据增强\n",
    "            seed = np.random.randint(0, 1000)  # 选择随机种子\n",
    "            img_generator = datagen.flow(np.array([img]), batch_size=1, seed=seed)\n",
    "            label_generator = datagen.flow(np.array([label]), batch_size=1, seed=seed)\n",
    "\n",
    "            img_batch = img_generator.next()\n",
    "            label_batch = label_generator.next()\n",
    "\n",
    "            img_batch = cv2.cvtColor(img_batch[0], cv2.COLOR_RGB2BGR)\n",
    "            label_batch = cv2.cvtColor(label_batch[0], cv2.COLOR_RGB2BGR)\n",
    "\n",
    "            augmented_img_filename = os.path.join(output_image_folder, f\"img_{i}aug{j}_{input_image_filename}\")\n",
    "            augmented_label_filename = os.path.join(output_label_folder, f\"label_{i}aug{j}_{input_label_filename}\")\n",
    "\n",
    "            cv2.imwrite(augmented_img_filename, img_batch)\n",
    "            cv2.imwrite(augmented_label_filename, label_batch)\n",
    "\n",
    "            augmented_images.append(img_batch)\n",
    "            augmented_labels.append(label_batch)\n",
    "            augmented_image_paths.append(augmented_img_filename)\n",
    "            augmented_label_paths.append(augmented_label_filename)\n",
    "\n",
    "    return augmented_images, augmented_labels, augmented_image_paths, augmented_label_paths\n",
    "\n",
    "\n",
    "def display_augmented_data(augmented_images, augmented_labels, num_samples=9):\n",
    "    # 随机选择 num_samples 张图像进行显示\n",
    "    random_indices = random.sample(range(len(augmented_images)), num_samples)\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    for i, idx in enumerate(random_indices):\n",
    "        img_batch = augmented_images[idx]\n",
    "        label_batch = augmented_labels[idx]\n",
    "\n",
    "        img_batch = img_batch / 255.0\n",
    "        label_batch = label_batch / 255.0\n",
    "\n",
    "        plt.subplot(3, 6, i * 2 + 1)  # 输出图像\n",
    "        plt.imshow(img_batch)\n",
    "        plt.title(f\"Image {i + 1}\")\n",
    "        plt.axis('off')\n",
    "\n",
    "        plt.subplot(3, 6, i * 2 + 2)  # 输出标签\n",
    "        plt.imshow(label_batch)\n",
    "        plt.title(f\"Label {i + 1}\")\n",
    "        plt.axis('off')\n",
    "\n",
    "    plt.show()\n",
    "#資料擴增後的存檔路徑\n",
    "\n",
    "output_image_folder = \"test_img\"\n",
    "output_label_folder = \"test_label\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "載入原圖片資料夾 與 結合資料擴增的函示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 修改 create_data_generator 函数\n",
    "def create_data_generator(img_folder, label_folder, val_folder, valmask_folder, prefix_to_keep, img_size, batch_size):\n",
    "    train_img_paths, train_label_paths = get_paths_with_prefix(img_folder, label_folder, prefix_to_keep)\n",
    "    val_img_paths, val_label_paths = get_paths_with_prefix(val_folder, valmask_folder, prefix_to_keep)\n",
    "    #print(val_img_paths)\n",
    "    # 数据增强\n",
    "    augmented_images, augmented_labels,aug_image_paths,aug_label_paths = augment_data(img_folder, label_folder, output_image_folder, output_label_folder)\n",
    "    display_augmented_data(augmented_images, augmented_labels)\n",
    "    #merged_images, merged_labels = combine_images_and_labels(augmented_images, augmented_labels, img_folder, label_folder)\n",
    "   \n",
    "    #print(\"images Shape:\",np.array(merged_images).shape)      \n",
    "    #print(\"images Shape:\",np.array(merged_labels).shape)\n",
    "    \n",
    "    merged_images=train_img_paths+aug_image_paths\n",
    "    merged_labels=train_label_paths+aug_label_paths\n",
    "    \n",
    "    \n",
    "    # 创建数据生成器\n",
    "    train_generator = DataGenerator_for_two_branch(\n",
    "        img_paths=merged_images,\n",
    "        label_paths=merged_labels,\n",
    "        img_size=img_size,\n",
    "        batch_size=batch_size\n",
    "    )\n",
    "\n",
    "    val_generator = DataGenerator_for_two_branch(\n",
    "        img_paths=val_img_paths,\n",
    "        label_paths=val_label_paths,\n",
    "        img_size=img_size,\n",
    "        batch_size=batch_size\n",
    "    )\n",
    "\n",
    "    return train_generator, val_generator\n",
    "\n",
    "#prefix_to_keep=\"\"\n",
    "#train_generator, val_generator = create_data_generator(img_folder, label_folder, val_folder, valmask_folder, prefix_to_keep, img_size, batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data_generator(img_folder, label_folder, val_folder, valmask_folder, prefix_to_keep, img_size, batch_size):\n",
    "    train_img_paths, train_label_paths = get_paths_with_prefix(img_folder, label_folder, prefix_to_keep)\n",
    "    val_img_paths, val_label_paths = get_paths_with_prefix(val_folder, valmask_folder, prefix_to_keep)\n",
    "\n",
    "    \n",
    "    \n",
    "    # 创建数据生成器\n",
    "    train_generator = DataGenerator_for_two_branch(\n",
    "        img_paths=train_img_paths,\n",
    "        label_paths=train_label_paths,\n",
    "        img_size=img_size,\n",
    "        batch_size=batch_size\n",
    "    )\n",
    "\n",
    "    val_generator = DataGenerator_for_two_branch(\n",
    "        img_paths=val_img_paths,\n",
    "        label_paths=val_label_paths,\n",
    "        img_size=img_size,\n",
    "        batch_size=batch_size\n",
    "    )\n",
    "\n",
    "    return train_generator, val_generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "18q3ti0OUhvi"
   },
   "source": [
    "Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#训练模型\n",
    "def train_model(train_generator, val_generator, model, checkpoint_filepath, epochs):\n",
    "# 创建 Adam 优化器并设置学习率\n",
    "    custom_optimizer = Adam(learning_rate=0.00001)\n",
    "# 使用自定义的优化器来编译模型\n",
    "    model.compile(optimizer=custom_optimizer, loss='binary_crossentropy', metrics=[\"accuracy\"],run_eagerly= True)\n",
    "    checkpoint_callback = ModelCheckpoint(filepath=checkpoint_filepath,\n",
    "                                          save_best_only=True,  \n",
    "                                          monitor='loss',  \n",
    "                                          mode='min',  \n",
    "                                          verbose=1)  \n",
    "     \n",
    "    history = model.fit(\n",
    "        train_generator,\n",
    "        validation_data=val_generator,\n",
    "        epochs=epochs,\n",
    "        callbacks=[checkpoint_callback]\n",
    "        )\n",
    "    show_history(history, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "def delete_all_files_in_folder(folder_path):\n",
    "    # 检查文件夹是否存在\n",
    "    if not os.path.exists(folder_path):\n",
    "        print(f\"Folder does not exist: {folder_path}\")\n",
    "        return\n",
    "\n",
    "    # 遍历文件夹内的所有文件并删除它们\n",
    "    for filename in os.listdir(folder_path):\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        if os.path.isfile(file_path):\n",
    "            try:\n",
    "                os.remove(file_path)\n",
    "                print(f\"Deleted: {file_path}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error deleting {file_path}: {str(e)}\")\n",
    "\n",
    "# 调用函数来删除指定文件夹内的所有文件\n",
    "delete_all_files_in_folder(\"test_img\")\n",
    "delete_all_files_in_folder(\"test_label\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "圖像数量为: 70 70 25 25\n"
     ]
    }
   ],
   "source": [
    "prefix = \"CFD\"\n",
    "train_gen, val_gen= create_data_generator(img_folder, label_folder, val_folder, valmask_folder, prefix, img_size, batch_size)\n",
    "Print(train_gen,val_gen)\n",
    "#show_random_images(train_gen.img_paths, train_gen.label_paths, num_samples=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1/8 [==>...........................] - ETA: 1:56 - loss: 0.6247 - accuracy: 0.7488"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "OOM when allocating tensor with shape[8,64,256,256] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc [Op:FusedBatchNormV3]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32md:\\Users\\ru83m\\Desktop\\CFD_train\\augdata.ipynb 儲存格 20\u001b[0m line \u001b[0;36m3\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Users/ru83m/Desktop/CFD_train/augdata.ipynb#X24sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m prefix\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mCFD\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Users/ru83m/Desktop/CFD_train/augdata.ipynb#X24sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m checkpoint_filepath \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mprefix\u001b[39m}\u001b[39;00m\u001b[39mnonaug_model.h5\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/Users/ru83m/Desktop/CFD_train/augdata.ipynb#X24sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m train_model(train_gen,val_gen , model, checkpoint_filepath, epochs\u001b[39m=\u001b[39;49m\u001b[39m30\u001b[39;49m)\n",
      "\u001b[1;32md:\\Users\\ru83m\\Desktop\\CFD_train\\augdata.ipynb 儲存格 20\u001b[0m line \u001b[0;36m1\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Users/ru83m/Desktop/CFD_train/augdata.ipynb#X24sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m model\u001b[39m.\u001b[39mcompile(optimizer\u001b[39m=\u001b[39mcustom_optimizer, loss\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mbinary_crossentropy\u001b[39m\u001b[39m'\u001b[39m, metrics\u001b[39m=\u001b[39m[\u001b[39m\"\u001b[39m\u001b[39maccuracy\u001b[39m\u001b[39m\"\u001b[39m],run_eagerly\u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Users/ru83m/Desktop/CFD_train/augdata.ipynb#X24sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m checkpoint_callback \u001b[39m=\u001b[39m ModelCheckpoint(filepath\u001b[39m=\u001b[39mcheckpoint_filepath,\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Users/ru83m/Desktop/CFD_train/augdata.ipynb#X24sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m                                       save_best_only\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,  \n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Users/ru83m/Desktop/CFD_train/augdata.ipynb#X24sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m                                       monitor\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mloss\u001b[39m\u001b[39m'\u001b[39m,  \n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Users/ru83m/Desktop/CFD_train/augdata.ipynb#X24sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m                                       mode\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mmin\u001b[39m\u001b[39m'\u001b[39m,  \n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Users/ru83m/Desktop/CFD_train/augdata.ipynb#X24sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m                                       verbose\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)  \n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/Users/ru83m/Desktop/CFD_train/augdata.ipynb#X24sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m history \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit(\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Users/ru83m/Desktop/CFD_train/augdata.ipynb#X24sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m     train_generator,\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Users/ru83m/Desktop/CFD_train/augdata.ipynb#X24sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m     validation_data\u001b[39m=\u001b[39;49mval_generator,\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Users/ru83m/Desktop/CFD_train/augdata.ipynb#X24sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m     epochs\u001b[39m=\u001b[39;49mepochs,\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Users/ru83m/Desktop/CFD_train/augdata.ipynb#X24sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m     callbacks\u001b[39m=\u001b[39;49m[checkpoint_callback]\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Users/ru83m/Desktop/CFD_train/augdata.ipynb#X24sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m     )\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Users/ru83m/Desktop/CFD_train/augdata.ipynb#X24sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m show_history(history, \u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\ru83m\\anaconda3\\envs\\unet_tf26\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1193\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1186\u001b[0m \u001b[39mwith\u001b[39;00m trace\u001b[39m.\u001b[39mTrace(\n\u001b[0;32m   1187\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m   1188\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[0;32m   1189\u001b[0m     step_num\u001b[39m=\u001b[39mstep,\n\u001b[0;32m   1190\u001b[0m     batch_size\u001b[39m=\u001b[39mbatch_size,\n\u001b[0;32m   1191\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m):\n\u001b[0;32m   1192\u001b[0m   callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1193\u001b[0m   tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[0;32m   1194\u001b[0m   \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[0;32m   1195\u001b[0m     context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[1;32mc:\\Users\\ru83m\\anaconda3\\envs\\unet_tf26\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:862\u001b[0m, in \u001b[0;36mModel.make_train_function.<locals>.train_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m    860\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtrain_function\u001b[39m(iterator):\n\u001b[0;32m    861\u001b[0m \u001b[39m  \u001b[39m\u001b[39m\"\"\"Runs a training execution with one step.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 862\u001b[0m   \u001b[39mreturn\u001b[39;00m step_function(\u001b[39mself\u001b[39;49m, iterator)\n",
      "File \u001b[1;32mc:\\Users\\ru83m\\anaconda3\\envs\\unet_tf26\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:852\u001b[0m, in \u001b[0;36mModel.make_train_function.<locals>.step_function\u001b[1;34m(model, iterator)\u001b[0m\n\u001b[0;32m    849\u001b[0m   \u001b[39mreturn\u001b[39;00m outputs\n\u001b[0;32m    851\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39m(iterator)\n\u001b[1;32m--> 852\u001b[0m outputs \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mdistribute_strategy\u001b[39m.\u001b[39;49mrun(run_step, args\u001b[39m=\u001b[39;49m(data,))\n\u001b[0;32m    853\u001b[0m outputs \u001b[39m=\u001b[39m reduce_per_replica(\n\u001b[0;32m    854\u001b[0m     outputs, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdistribute_strategy, reduction\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mfirst\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m    855\u001b[0m write_scalar_summaries(outputs, step\u001b[39m=\u001b[39mmodel\u001b[39m.\u001b[39m_train_counter)  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\ru83m\\anaconda3\\envs\\unet_tf26\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:1286\u001b[0m, in \u001b[0;36mStrategyBase.run\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m   1281\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mscope():\n\u001b[0;32m   1282\u001b[0m   \u001b[39m# tf.distribute supports Eager functions, so AutoGraph should not be\u001b[39;00m\n\u001b[0;32m   1283\u001b[0m   \u001b[39m# applied when the caller is also in Eager mode.\u001b[39;00m\n\u001b[0;32m   1284\u001b[0m   fn \u001b[39m=\u001b[39m autograph\u001b[39m.\u001b[39mtf_convert(\n\u001b[0;32m   1285\u001b[0m       fn, autograph_ctx\u001b[39m.\u001b[39mcontrol_status_ctx(), convert_by_default\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m-> 1286\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_extended\u001b[39m.\u001b[39;49mcall_for_each_replica(fn, args\u001b[39m=\u001b[39;49margs, kwargs\u001b[39m=\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\ru83m\\anaconda3\\envs\\unet_tf26\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2849\u001b[0m, in \u001b[0;36mStrategyExtendedV1.call_for_each_replica\u001b[1;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[0;32m   2847\u001b[0m   kwargs \u001b[39m=\u001b[39m {}\n\u001b[0;32m   2848\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_container_strategy()\u001b[39m.\u001b[39mscope():\n\u001b[1;32m-> 2849\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_for_each_replica(fn, args, kwargs)\n",
      "File \u001b[1;32mc:\\Users\\ru83m\\anaconda3\\envs\\unet_tf26\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:3632\u001b[0m, in \u001b[0;36m_DefaultDistributionExtended._call_for_each_replica\u001b[1;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[0;32m   3630\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_call_for_each_replica\u001b[39m(\u001b[39mself\u001b[39m, fn, args, kwargs):\n\u001b[0;32m   3631\u001b[0m   \u001b[39mwith\u001b[39;00m ReplicaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_container_strategy(), replica_id_in_sync_group\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m):\n\u001b[1;32m-> 3632\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\ru83m\\anaconda3\\envs\\unet_tf26\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:597\u001b[0m, in \u001b[0;36mcall_with_unspecified_conversion_status.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    595\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapper\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m    596\u001b[0m   \u001b[39mwith\u001b[39;00m ag_ctx\u001b[39m.\u001b[39mControlStatusCtx(status\u001b[39m=\u001b[39mag_ctx\u001b[39m.\u001b[39mStatus\u001b[39m.\u001b[39mUNSPECIFIED):\n\u001b[1;32m--> 597\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\ru83m\\anaconda3\\envs\\unet_tf26\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:845\u001b[0m, in \u001b[0;36mModel.make_train_function.<locals>.step_function.<locals>.run_step\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m    844\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrun_step\u001b[39m(data):\n\u001b[1;32m--> 845\u001b[0m   outputs \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mtrain_step(data)\n\u001b[0;32m    846\u001b[0m   \u001b[39m# Ensure counter is updated only if `train_step` succeeds.\u001b[39;00m\n\u001b[0;32m    847\u001b[0m   \u001b[39mwith\u001b[39;00m ops\u001b[39m.\u001b[39mcontrol_dependencies(_minimum_control_deps(outputs)):\n",
      "File \u001b[1;32mc:\\Users\\ru83m\\anaconda3\\envs\\unet_tf26\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:802\u001b[0m, in \u001b[0;36mModel.train_step\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m    800\u001b[0m \u001b[39m# Run forward pass.\u001b[39;00m\n\u001b[0;32m    801\u001b[0m \u001b[39mwith\u001b[39;00m backprop\u001b[39m.\u001b[39mGradientTape() \u001b[39mas\u001b[39;00m tape:\n\u001b[1;32m--> 802\u001b[0m   y_pred \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m(x, training\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[0;32m    803\u001b[0m   loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcompiled_loss(\n\u001b[0;32m    804\u001b[0m       y, y_pred, sample_weight, regularization_losses\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlosses)\n\u001b[0;32m    805\u001b[0m \u001b[39m# Run backwards pass.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\ru83m\\anaconda3\\envs\\unet_tf26\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py:1057\u001b[0m, in \u001b[0;36mLayer.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1053\u001b[0m   inputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_cast_inputs(inputs, input_list)\n\u001b[0;32m   1055\u001b[0m \u001b[39mwith\u001b[39;00m autocast_variable\u001b[39m.\u001b[39menable_auto_cast_variables(\n\u001b[0;32m   1056\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compute_dtype_object):\n\u001b[1;32m-> 1057\u001b[0m   outputs \u001b[39m=\u001b[39m call_fn(inputs, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1059\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_activity_regularizer:\n\u001b[0;32m   1060\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_handle_activity_regularization(inputs, outputs)\n",
      "File \u001b[1;32mc:\\Users\\ru83m\\anaconda3\\envs\\unet_tf26\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\functional.py:420\u001b[0m, in \u001b[0;36mFunctional.call\u001b[1;34m(self, inputs, training, mask)\u001b[0m\n\u001b[0;32m    401\u001b[0m \u001b[39m@doc_controls\u001b[39m\u001b[39m.\u001b[39mdo_not_doc_inheritable\n\u001b[0;32m    402\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcall\u001b[39m(\u001b[39mself\u001b[39m, inputs, training\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, mask\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m    403\u001b[0m \u001b[39m  \u001b[39m\u001b[39m\"\"\"Calls the model on new inputs.\u001b[39;00m\n\u001b[0;32m    404\u001b[0m \n\u001b[0;32m    405\u001b[0m \u001b[39m  In this case `call` just reapplies\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    418\u001b[0m \u001b[39m      a list of tensors if there are more than one outputs.\u001b[39;00m\n\u001b[0;32m    419\u001b[0m \u001b[39m  \"\"\"\u001b[39;00m\n\u001b[1;32m--> 420\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_internal_graph(\n\u001b[0;32m    421\u001b[0m       inputs, training\u001b[39m=\u001b[39;49mtraining, mask\u001b[39m=\u001b[39;49mmask)\n",
      "File \u001b[1;32mc:\\Users\\ru83m\\anaconda3\\envs\\unet_tf26\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\functional.py:556\u001b[0m, in \u001b[0;36mFunctional._run_internal_graph\u001b[1;34m(self, inputs, training, mask)\u001b[0m\n\u001b[0;32m    553\u001b[0m   \u001b[39mcontinue\u001b[39;00m  \u001b[39m# Node is not computable, try skipping.\u001b[39;00m\n\u001b[0;32m    555\u001b[0m args, kwargs \u001b[39m=\u001b[39m node\u001b[39m.\u001b[39mmap_arguments(tensor_dict)\n\u001b[1;32m--> 556\u001b[0m outputs \u001b[39m=\u001b[39m node\u001b[39m.\u001b[39mlayer(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    558\u001b[0m \u001b[39m# Update tensor_dict.\u001b[39;00m\n\u001b[0;32m    559\u001b[0m \u001b[39mfor\u001b[39;00m x_id, y \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(node\u001b[39m.\u001b[39mflat_output_ids, nest\u001b[39m.\u001b[39mflatten(outputs)):\n",
      "File \u001b[1;32mc:\\Users\\ru83m\\anaconda3\\envs\\unet_tf26\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py:1057\u001b[0m, in \u001b[0;36mLayer.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1053\u001b[0m   inputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_cast_inputs(inputs, input_list)\n\u001b[0;32m   1055\u001b[0m \u001b[39mwith\u001b[39;00m autocast_variable\u001b[39m.\u001b[39menable_auto_cast_variables(\n\u001b[0;32m   1056\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compute_dtype_object):\n\u001b[1;32m-> 1057\u001b[0m   outputs \u001b[39m=\u001b[39m call_fn(inputs, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1059\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_activity_regularizer:\n\u001b[0;32m   1060\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_handle_activity_regularization(inputs, outputs)\n",
      "File \u001b[1;32mc:\\Users\\ru83m\\anaconda3\\envs\\unet_tf26\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\normalization\\batch_normalization.py:770\u001b[0m, in \u001b[0;36mBatchNormalizationBase.call\u001b[1;34m(self, inputs, training)\u001b[0m\n\u001b[0;32m    767\u001b[0m     \u001b[39mreturn\u001b[39;00m outputs\n\u001b[0;32m    769\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfused:\n\u001b[1;32m--> 770\u001b[0m   outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fused_batch_norm(inputs, training\u001b[39m=\u001b[39;49mtraining)\n\u001b[0;32m    771\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvirtual_batch_size \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    772\u001b[0m     \u001b[39m# Currently never reaches here since fused_batch_norm does not support\u001b[39;00m\n\u001b[0;32m    773\u001b[0m     \u001b[39m# virtual batching\u001b[39;00m\n\u001b[0;32m    774\u001b[0m     outputs \u001b[39m=\u001b[39m undo_virtual_batching(outputs)\n",
      "File \u001b[1;32mc:\\Users\\ru83m\\anaconda3\\envs\\unet_tf26\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\normalization\\batch_normalization.py:623\u001b[0m, in \u001b[0;36mBatchNormalizationBase._fused_batch_norm\u001b[1;34m(self, inputs, training)\u001b[0m\n\u001b[0;32m    618\u001b[0m   train_op \u001b[39m=\u001b[39m \u001b[39mlambda\u001b[39;00m: control_flow_util\u001b[39m.\u001b[39msmart_cond(\n\u001b[0;32m    619\u001b[0m       input_batch_size \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m, _fused_batch_norm_training,\n\u001b[0;32m    620\u001b[0m       _fused_batch_norm_training_empty)\n\u001b[0;32m    621\u001b[0m   \u001b[39m# pylint: enable=g-long-lambda\u001b[39;00m\n\u001b[1;32m--> 623\u001b[0m output, mean, variance \u001b[39m=\u001b[39m control_flow_util\u001b[39m.\u001b[39;49msmart_cond(\n\u001b[0;32m    624\u001b[0m     training, train_op, _fused_batch_norm_inference)\n\u001b[0;32m    625\u001b[0m variance \u001b[39m=\u001b[39m _maybe_add_or_remove_bessels_correction(variance, remove\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m    627\u001b[0m training_value \u001b[39m=\u001b[39m control_flow_util\u001b[39m.\u001b[39mconstant_value(training)\n",
      "File \u001b[1;32mc:\\Users\\ru83m\\anaconda3\\envs\\unet_tf26\\lib\\site-packages\\tensorflow\\python\\keras\\utils\\control_flow_util.py:109\u001b[0m, in \u001b[0;36msmart_cond\u001b[1;34m(pred, true_fn, false_fn, name)\u001b[0m\n\u001b[0;32m    106\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(pred, variables\u001b[39m.\u001b[39mVariable):\n\u001b[0;32m    107\u001b[0m   \u001b[39mreturn\u001b[39;00m control_flow_ops\u001b[39m.\u001b[39mcond(\n\u001b[0;32m    108\u001b[0m       pred, true_fn\u001b[39m=\u001b[39mtrue_fn, false_fn\u001b[39m=\u001b[39mfalse_fn, name\u001b[39m=\u001b[39mname)\n\u001b[1;32m--> 109\u001b[0m \u001b[39mreturn\u001b[39;00m smart_module\u001b[39m.\u001b[39;49msmart_cond(\n\u001b[0;32m    110\u001b[0m     pred, true_fn\u001b[39m=\u001b[39;49mtrue_fn, false_fn\u001b[39m=\u001b[39;49mfalse_fn, name\u001b[39m=\u001b[39;49mname)\n",
      "File \u001b[1;32mc:\\Users\\ru83m\\anaconda3\\envs\\unet_tf26\\lib\\site-packages\\tensorflow\\python\\framework\\smart_cond.py:56\u001b[0m, in \u001b[0;36msmart_cond\u001b[1;34m(pred, true_fn, false_fn, name)\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[39mif\u001b[39;00m pred_value \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m     55\u001b[0m   \u001b[39mif\u001b[39;00m pred_value:\n\u001b[1;32m---> 56\u001b[0m     \u001b[39mreturn\u001b[39;00m true_fn()\n\u001b[0;32m     57\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     58\u001b[0m     \u001b[39mreturn\u001b[39;00m false_fn()\n",
      "File \u001b[1;32mc:\\Users\\ru83m\\anaconda3\\envs\\unet_tf26\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\normalization\\batch_normalization.py:589\u001b[0m, in \u001b[0;36mBatchNormalizationBase._fused_batch_norm.<locals>._fused_batch_norm_training\u001b[1;34m()\u001b[0m\n\u001b[0;32m    588\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_fused_batch_norm_training\u001b[39m():\n\u001b[1;32m--> 589\u001b[0m   \u001b[39mreturn\u001b[39;00m nn\u001b[39m.\u001b[39;49mfused_batch_norm(\n\u001b[0;32m    590\u001b[0m       inputs,\n\u001b[0;32m    591\u001b[0m       gamma,\n\u001b[0;32m    592\u001b[0m       beta,\n\u001b[0;32m    593\u001b[0m       mean\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmoving_mean,\n\u001b[0;32m    594\u001b[0m       variance\u001b[39m=\u001b[39;49m_maybe_add_or_remove_bessels_correction(\n\u001b[0;32m    595\u001b[0m           \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmoving_variance, remove\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m),\n\u001b[0;32m    596\u001b[0m       epsilon\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mepsilon,\n\u001b[0;32m    597\u001b[0m       is_training\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[0;32m    598\u001b[0m       data_format\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_data_format,\n\u001b[0;32m    599\u001b[0m       exponential_avg_factor\u001b[39m=\u001b[39;49mexponential_avg_factor)\n",
      "File \u001b[1;32mc:\\Users\\ru83m\\anaconda3\\envs\\unet_tf26\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:206\u001b[0m, in \u001b[0;36madd_dispatch_support.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    204\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[39;00m\n\u001b[0;32m    205\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 206\u001b[0m   \u001b[39mreturn\u001b[39;00m target(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    207\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mTypeError\u001b[39;00m, \u001b[39mValueError\u001b[39;00m):\n\u001b[0;32m    208\u001b[0m   \u001b[39m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[39;00m\n\u001b[0;32m    209\u001b[0m   \u001b[39m# TypeError, when given unexpected types.  So we need to catch both.\u001b[39;00m\n\u001b[0;32m    210\u001b[0m   result \u001b[39m=\u001b[39m dispatch(wrapper, args, kwargs)\n",
      "File \u001b[1;32mc:\\Users\\ru83m\\anaconda3\\envs\\unet_tf26\\lib\\site-packages\\tensorflow\\python\\ops\\nn_impl.py:1668\u001b[0m, in \u001b[0;36mfused_batch_norm\u001b[1;34m(x, scale, offset, mean, variance, epsilon, data_format, is_training, name, exponential_avg_factor)\u001b[0m\n\u001b[0;32m   1665\u001b[0m min_epsilon \u001b[39m=\u001b[39m \u001b[39m1.001e-5\u001b[39m\n\u001b[0;32m   1666\u001b[0m epsilon \u001b[39m=\u001b[39m epsilon \u001b[39mif\u001b[39;00m epsilon \u001b[39m>\u001b[39m min_epsilon \u001b[39melse\u001b[39;00m min_epsilon\n\u001b[1;32m-> 1668\u001b[0m y, running_mean, running_var, _, _, _ \u001b[39m=\u001b[39m gen_nn_ops\u001b[39m.\u001b[39;49mfused_batch_norm_v3(\n\u001b[0;32m   1669\u001b[0m     x,\n\u001b[0;32m   1670\u001b[0m     scale,\n\u001b[0;32m   1671\u001b[0m     offset,\n\u001b[0;32m   1672\u001b[0m     mean,\n\u001b[0;32m   1673\u001b[0m     variance,\n\u001b[0;32m   1674\u001b[0m     epsilon\u001b[39m=\u001b[39;49mepsilon,\n\u001b[0;32m   1675\u001b[0m     exponential_avg_factor\u001b[39m=\u001b[39;49mexponential_avg_factor,\n\u001b[0;32m   1676\u001b[0m     data_format\u001b[39m=\u001b[39;49mdata_format,\n\u001b[0;32m   1677\u001b[0m     is_training\u001b[39m=\u001b[39;49mis_training,\n\u001b[0;32m   1678\u001b[0m     name\u001b[39m=\u001b[39;49mname)\n\u001b[0;32m   1679\u001b[0m \u001b[39mreturn\u001b[39;00m y, running_mean, running_var\n",
      "File \u001b[1;32mc:\\Users\\ru83m\\anaconda3\\envs\\unet_tf26\\lib\\site-packages\\tensorflow\\python\\ops\\gen_nn_ops.py:4269\u001b[0m, in \u001b[0;36mfused_batch_norm_v3\u001b[1;34m(x, scale, offset, mean, variance, epsilon, exponential_avg_factor, data_format, is_training, name)\u001b[0m\n\u001b[0;32m   4267\u001b[0m   \u001b[39mreturn\u001b[39;00m _result\n\u001b[0;32m   4268\u001b[0m \u001b[39mexcept\u001b[39;00m _core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m-> 4269\u001b[0m   _ops\u001b[39m.\u001b[39;49mraise_from_not_ok_status(e, name)\n\u001b[0;32m   4270\u001b[0m \u001b[39mexcept\u001b[39;00m _core\u001b[39m.\u001b[39m_FallbackException:\n\u001b[0;32m   4271\u001b[0m   \u001b[39mpass\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\ru83m\\anaconda3\\envs\\unet_tf26\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:6941\u001b[0m, in \u001b[0;36mraise_from_not_ok_status\u001b[1;34m(e, name)\u001b[0m\n\u001b[0;32m   6939\u001b[0m message \u001b[39m=\u001b[39m e\u001b[39m.\u001b[39mmessage \u001b[39m+\u001b[39m (\u001b[39m\"\u001b[39m\u001b[39m name: \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m name \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   6940\u001b[0m \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m-> 6941\u001b[0m six\u001b[39m.\u001b[39;49mraise_from(core\u001b[39m.\u001b[39;49m_status_to_exception(e\u001b[39m.\u001b[39;49mcode, message), \u001b[39mNone\u001b[39;49;00m)\n",
      "File \u001b[1;32m<string>:3\u001b[0m, in \u001b[0;36mraise_from\u001b[1;34m(value, from_value)\u001b[0m\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[8,64,256,256] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc [Op:FusedBatchNormV3]"
     ]
    }
   ],
   "source": [
    "prefix=\"CFD\"\n",
    "checkpoint_filepath = f'{prefix}nonaug_model.h5'\n",
    "train_model(train_gen,val_gen , model, checkpoint_filepath, epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMsiefs8epaQ4yy1sKyEp1i",
   "mount_file_id": "1N0kV3fnNmCowfZszAFtQPagpmIJizelA",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
